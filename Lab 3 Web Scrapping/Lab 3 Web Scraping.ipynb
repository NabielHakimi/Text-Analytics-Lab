{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36d254e9-a62c-4829-a17b-71760051fbf6",
   "metadata": {},
   "source": [
    "### Scraping for Simple Web Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "665d843e-aed0-4938-9741-552a48bc1ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49f72e3e-250a-40ba-a355-8fef894dab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://dataquestio.github.io/web-scraping-pages/simple.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb5ef0a9-4082-49b3-83c2-98a93ed97a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb165daf-17ca-4eb9-a79e-7c9feb68e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(page.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c3442ff-8574-4a85-b7cc-9a9f82f3e8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['html',\n",
       " '\\n',\n",
       " <html>\n",
       " <head>\n",
       " <title>A simple example page</title>\n",
       " </head>\n",
       " <body>\n",
       " <p>Here is some simple content for this page.</p>\n",
       " </body>\n",
       " </html>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(soup.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aea4b24-d64a-4082-9b19-45bfed57e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = list(soup.children)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d27d5a6-a77b-4df1-8efe-6cbf4ab35808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<p>Here is some simple content for this page.</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6e4f5c9-727b-4772-bc48-0362a70bcf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = soup.find('p').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58a2edf1-3160-4ec6-aa6e-1789e473d29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Content: Here is some simple content for this page.\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracted Content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f8b0990-b7cd-47c9-8ba7-daec0893a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"extracted_data1.txt\",\"w\") as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efaca18-4885-4632-9127-6dcc1cc38b02",
   "metadata": {},
   "source": [
    "### Print Specific Content of A Single Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8d11780-f4e1-4032-8b32-bb46fb493181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "296d18d5-e6d9-406e-93b0-fbaf1931cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a GET request to the website\n",
    "page = requests.get('https://quotes.toscrape.com')\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "# Create a list to store quotes\n",
    "quotes = []\n",
    "# Find all quote elements\n",
    "quote_elements = soup.find_all('div', class_='quote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d60ea9bb-ce0f-49c4-8e97-158415b35606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract information from each quote element\n",
    "for quote_element in quote_elements:\n",
    " # extract the text of the quote\n",
    " text = quote_element.find('span', class_='text').text\n",
    " # extract the author of the quote\n",
    " author = quote_element.find('small', class_='author').text\n",
    " # extract the tag <a> HTML elements related to the quote\n",
    " tag_elements = quote_element.select('.tags .tag')\n",
    " # store the list of tag strings in a list\n",
    " tags = []\n",
    " for tag_element in tag_elements:\n",
    "     tags.append(tag_element.text)\n",
    "\n",
    " quotes.append(\n",
    " {\n",
    " 'text': text,\n",
    " 'author': author,\n",
    " 'tags': ', '.join(tags) # merge the tags into a \"A, B, ..., Z\" string\n",
    " }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad83aa76-43aa-4a5d-83a3-72fc453004b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quote:  “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "Author:  Albert Einstein\n",
      "Tags:  change, deep-thoughts, thinking, world\n",
      "\n",
      "Quote:  “It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "Author:  J.K. Rowling\n",
      "Tags:  abilities, choices\n",
      "\n",
      "Quote:  “There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "Author:  Albert Einstein\n",
      "Tags:  inspirational, life, live, miracle, miracles\n",
      "\n",
      "Quote:  “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "Author:  Jane Austen\n",
      "Tags:  aliteracy, books, classic, humor\n",
      "\n",
      "Quote:  “Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "Author:  Marilyn Monroe\n",
      "Tags:  be-yourself, inspirational\n",
      "\n",
      "Quote:  “Try not to become a man of success. Rather become a man of value.”\n",
      "Author:  Albert Einstein\n",
      "Tags:  adulthood, success, value\n",
      "\n",
      "Quote:  “It is better to be hated for what you are than to be loved for what you are not.”\n",
      "Author:  André Gide\n",
      "Tags:  life, love\n",
      "\n",
      "Quote:  “I have not failed. I've just found 10,000 ways that won't work.”\n",
      "Author:  Thomas A. Edison\n",
      "Tags:  edison, failure, inspirational, paraphrased\n",
      "\n",
      "Quote:  “A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "Author:  Eleanor Roosevelt\n",
      "Tags:  misattributed-eleanor-roosevelt\n",
      "\n",
      "Quote:  “A day without sunshine is like, you know, night.”\n",
      "Author:  Steve Martin\n",
      "Tags:  humor, obvious, simile\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the scraped quotes - optional\n",
    "for quote in quotes:\n",
    "    print(\"Quote: \", quote['text'])\n",
    "    print(\"Author: \", quote['author'])\n",
    "    print(\"Tags: \", quote['tags'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c02c00d6-100a-4e34-9a88-5320658276ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quotes have been saved to quotes.csv\n"
     ]
    }
   ],
   "source": [
    "# Save quotes to a CSV file\n",
    "with open('quotes.csv', 'w', encoding='utf-8', newline='') as csvfile:\n",
    "    fieldnames = ['text', 'author', 'tags']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    # Write headers\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # Write quotes\n",
    "    for quote in quotes:\n",
    "        writer.writerow(quote)\n",
    "\n",
    "print(\"Quotes have been saved to quotes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07e86ee-09cd-4c6b-8be2-d3c42ad9c761",
   "metadata": {},
   "source": [
    "### Print Specific Content of Multiple Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffaf0d98-2b5a-4340-8378-de000afb9ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d931cbb7-3f7a-4a87-9971-7ee828137076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape quotes from a page\n",
    "def scrape_page(soup, quotes):\n",
    " for quote in soup.find_all('div', class_='quote'):\n",
    "     text = quote.find('span', class_='text').text\n",
    "     author = quote.find('small', class_='author').text\n",
    "     tags = ', '.join(tag.text for tag in quote.find_all('a', class_='tag'))\n",
    "     quotes.append({'Text': text, 'Author': author, 'Tags': tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac5c57bc-1aaf-40ba-a985-40280111a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL and headers\n",
    "base_url = 'https://quotes.toscrape.com'\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "# List to store quotes\n",
    "quotes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50a549be-372a-4a8a-aa05-2378f59f2955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape quotes from multiple pages\n",
    "def scrape_all_pages(url):\n",
    " while url:\n",
    "     response = requests.get(url, headers=headers)\n",
    "     soup = BeautifulSoup(response.text, 'html.parser')\n",
    "     scrape_page(soup, quotes)\n",
    "     next_page = soup.find('li', class_='next')\n",
    "     url = base_url + next_page.find('a')['href'] if next_page else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c97f4741-99ad-4115-8804-3bee6923f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape quotes from all pages\n",
    "scrape_all_pages(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80388326-8240-4371-8852-848344ab721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save quotes to CSV file\n",
    "with open('quotes2.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    " writer = csv.DictWriter(csvfile, fieldnames=['Text', 'Author', 'Tags'])\n",
    " writer.writeheader()\n",
    " writer.writerows(quotes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
